{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f609be53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "unprocessed = pd.read_excel('../Datasets/Oneil_combination_response.xls')\n",
    "unprocessed['ic50'] = unprocessed['X/X0'].apply(lambda x: 1 if x>=.45 and x<=0.55 else 0 )\n",
    "unprocessed['new drugA Conc (µM)'] = np.log2(unprocessed['drugA Conc (µM)'])\n",
    "unprocessed['new drugB Conc (µM)'] = np.log2(unprocessed['drugB Conc (µM)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4247df",
   "metadata": {},
   "source": [
    "### Creating Drug-cell line matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae629c19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "def process_drug_combination_data(\n",
    "    df,\n",
    "    cell_line_col='cell_line',\n",
    "    combo_name_col='combination_name',\n",
    "    drugA_col='drugA Conc (µM)',\n",
    "    drugB_col='drugB Conc (µM)',\n",
    "    new_drugA_col='new drugA Conc (µM)',\n",
    "    new_drugB_col='new drugB Conc (µM)',\n",
    "    ic50_col='ic50',\n",
    "    threshold=0.5,\n",
    "    random_state=None\n",
    "):\n",
    "    \"\"\"\n",
    "    Process drug combination data to create complex concentration matrices.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    df : pd.DataFrame\n",
    "        Input dataframe containing drug combination data\n",
    "    cell_line_col : str\n",
    "        Column name for cell line identifiers\n",
    "    combo_name_col : str\n",
    "        Column name for combination identifiers\n",
    "    drugA_col, drugB_col : str\n",
    "        Columns for original drug concentrations\n",
    "    new_drugA_col, new_drugB_col : str\n",
    "        Columns for transformed drug concentrations\n",
    "    ic50_col : str\n",
    "        Column indicating IC50 values (1 = active)\n",
    "    threshold : float (0-1)\n",
    "        Threshold for dropping columns with too many missing values\n",
    "    random_state : int, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple of (pd.DataFrame, pd.DataFrame)\n",
    "        Returns two dataframes:\n",
    "        1. Processed matrix with new concentrations\n",
    "        2. Original concentration matrix\n",
    "    \"\"\"\n",
    "    \n",
    "    # Create mappings for drug concentrations\n",
    "    active_drugs = df[df[ic50_col] == 1]\n",
    "    l1 = active_drugs[drugA_col].value_counts().index.tolist()\n",
    "    l2 = active_drugs[drugB_col].value_counts().index.tolist()\n",
    "    \n",
    "    l1_mapping = {value: idx for idx, value in enumerate(l1)}\n",
    "    l2_mapping = {value: idx for idx, value in enumerate(l2)}\n",
    "    \n",
    "    # Create all possible cell line × combination pairs\n",
    "    names = pd.merge(\n",
    "        df[cell_line_col].drop_duplicates(),\n",
    "        df[combo_name_col].drop_duplicates(),\n",
    "        how='cross'\n",
    "    )\n",
    "    \n",
    "    # Initialize result dictionaries\n",
    "    new_conc_matrix = {}\n",
    "    orig_conc_matrix = {}\n",
    "    \n",
    "    # Process each cell line and combination\n",
    "    for _, row in tqdm(names.iterrows(), total=len(names)):\n",
    "        cell_line = row[cell_line_col]\n",
    "        combo = row[combo_name_col]\n",
    "        \n",
    "        if cell_line not in new_conc_matrix:\n",
    "            new_conc_matrix[cell_line] = []\n",
    "            orig_conc_matrix[cell_line] = []\n",
    "        \n",
    "        # Filter relevant data\n",
    "        mask = (\n",
    "            (df[cell_line_col] == cell_line) & \n",
    "            (df[combo_name_col] == combo) & \n",
    "            (df[ic50_col] == 1)\n",
    "        )\n",
    "        temp = df[mask]\n",
    "        \n",
    "        if temp.empty:\n",
    "            new_conc_matrix[cell_line].append(np.nan)\n",
    "            orig_conc_matrix[cell_line].append(np.nan)\n",
    "        else:\n",
    "            # Sort by drug concentrations\n",
    "            temp['sorting_key'] = temp.apply(\n",
    "                lambda x: (l1_mapping[x[drugA_col]], l2_mapping[x[drugB_col]]), \n",
    "                axis=1\n",
    "            )\n",
    "            temp = temp.sort_values('sorting_key').iloc[0]\n",
    "            \n",
    "            # Store as complex numbers\n",
    "            new_conc_matrix[cell_line].append(\n",
    "                complex(temp[new_drugA_col], temp[new_drugB_col])\n",
    "            )\n",
    "            orig_conc_matrix[cell_line].append(\n",
    "                complex(temp[drugA_col], temp[drugB_col])\n",
    "            )\n",
    "    \n",
    "    # Convert to dataframes\n",
    "    cols = unprocessed['combination_name'].unique().tolist()\n",
    "    \n",
    "    new_df = pd.DataFrame.from_dict(new_conc_matrix, orient='index', columns=cols)\n",
    "    orig_df = pd.DataFrame.from_dict(orig_conc_matrix, orient='index', columns=cols)\n",
    "    \n",
    "    # Apply threshold filtering\n",
    "    threshold_count = int(len(new_df) * threshold)\n",
    "    \n",
    "    new_df = new_df.dropna(thresh=threshold_count, axis=1).fillna(0)\n",
    "    orig_df = orig_df.dropna(thresh=threshold_count, axis=1).fillna(0)\n",
    "    \n",
    "    return new_df, orig_df\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# new_conc, orig_conc = process_drug_combination_data(unprocessed)\n",
    "# new_conc.to_csv('drug_cell_log_matrix.csv')\n",
    "# orig_conc.to_csv('drug_cell_matrix.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66af5556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 583/583 [00:02<00:00, 247.99it/s]\n"
     ]
    }
   ],
   "source": [
    "result, result2 = process_drug_combination_data(unprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74b34bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "result.to_csv('../Datasets/Oneil/Drug_CellLine_matrix_logartihm.csv')\n",
    "result2.to_csv('../Datasets/Oneil/Drug_CellLine_matrix.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab2fee92",
   "metadata": {},
   "source": [
    "### Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12bbd6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('../Datasets/Oneil/Drug_CellLine_matrix_logartihm.csv', index_col='Unnamed: 0')\n",
    "main_concs = pd.read_csv('../Datasets/Oneil/Drug_CellLine_matrix.csv', index_col='Unnamed: 0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb6c459",
   "metadata": {},
   "outputs": [],
   "source": [
    "## different mf method \n",
    "\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from tqdm import tqdm\n",
    "\n",
    "def pmf_with_bias(X, test, k, learning_rate, num_iterations, lambda_reg, sigma_sq):\n",
    "    \"\"\"\n",
    "    Probabilistic Matrix Factorization with user and item bias using stochastic gradient descent for complex numbers.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- Input matrix of shape (m, n) with complex numbers\n",
    "    test -- Test matrix of the same shape as X with complex numbers\n",
    "    k -- Number of latent features\n",
    "    learning_rate -- Learning rate for gradient descent\n",
    "    num_iterations -- Number of iterations for the optimization\n",
    "    lambda_reg -- Regularization strength\n",
    "    sigma_sq -- Variance of the complex Gaussian distribution\n",
    "    \n",
    "    Returns:\n",
    "    U -- Matrix of shape (m, k) representing the user latent factors (complex)\n",
    "    V -- Matrix of shape (n, k) representing the item latent factors (complex)\n",
    "    b_u -- Vector of shape (m,) representing the user bias terms (real)\n",
    "    b_v -- Vector of shape (n,) representing the item bias terms (real)\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Initialize U, V, b_u, and b_v with random values\n",
    "    U = np.random.normal(scale=1.0 / k, size=(m, k)).astype(complex)\n",
    "    V = np.random.normal(scale=1.0 / k, size=(n, k)).astype(complex)\n",
    "    b_u = np.random.normal(scale=1.0 / k, size= m).astype(complex) \n",
    "    b_v = np.random.normal(scale=1.0 / k, size=n).astype(complex)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if X[i,j]!=0:\n",
    "                    prediction = np.dot(U[i, :], V[j, :].conj()) + b_u[i] + b_v[j]\n",
    "                    error = X[i, j] - prediction\n",
    "                    grad_U = -error * V[j, :] + lambda_reg * U[i, :]\n",
    "                    grad_V = -error * U[i, :] + lambda_reg * V[j, :]\n",
    "                    grad_b_u = -error + lambda_reg * b_u[i]\n",
    "                    grad_b_v = -error + lambda_reg * b_v[j]\n",
    "\n",
    "                    U[i, :] -= learning_rate * grad_U\n",
    "                    V[j, :] -= learning_rate * grad_V\n",
    "                    b_u[i] -= learning_rate * grad_b_u\n",
    "                    b_v[j] -= learning_rate * grad_b_v\n",
    "\n",
    "                    prediction = np.clip(prediction, -14, 9)\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration : ' + str(iteration))\n",
    "            print('MAE train error')\n",
    "            mask = np.nonzero(X)\n",
    "            print(np.mean(abs(X[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask])))\n",
    "            mask = np.nonzero(test)\n",
    "            print('MAE test error')\n",
    "            print(np.mean(abs(test[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask])))\n",
    "\n",
    "            print('MSE train error')\n",
    "            mask = np.nonzero(X)\n",
    "            print(np.mean(pow(abs(X[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask]), 2)))\n",
    "            mask = np.nonzero(test)\n",
    "            print('MSE test error')\n",
    "            print(np.mean(pow(abs(test[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask]), 2)))\n",
    "\n",
    "        \n",
    "    return U, V, b_u, b_v\n",
    "\n",
    "ratings = data.to_numpy(dtype='complex')\n",
    "train = ratings.copy()\n",
    "test = ratings.copy()\n",
    "\n",
    "#u, v, b_u, b_v = kernel_matrix_factorization(train, test, 200, .0001, 1000, 0.001)\n",
    "U, V, b_u, b_v = pmf_with_bias(train, test, 700, 0.001, 300, 0.0001, 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2609cb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "\n",
    "\n",
    "ratings = data.to_numpy(dtype='complex')\n",
    "cv = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "count = 1\n",
    "result_np = ratings.copy()\n",
    "indexes = np.argwhere(result_np != complex(0,0))\n",
    "fold = 0\n",
    "\n",
    "for train_index, test_index in cv.split(indexes):\n",
    "    np.savetxt(f'train_index_fold_{fold}.txt', train_index, fmt='%d')\n",
    "    np.savetxt(f'test_index_fold_{fold}.txt', test_index, fmt='%d')\n",
    "    fold +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d38eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "for i in range(0, 5):\n",
    "    f = open(f'/home/abdollahimohammad/Downloads/final uni codes/test_index_fold_{i}.txt')\n",
    "    test_index = f.readlines()\n",
    "    temp = main_concs.to_numpy(dtype='complex')\n",
    "    indexes = np.where(temp!=complex(0,0))\n",
    "    test_indexes = []\n",
    "\n",
    "    for j in tqdm(test_index):\n",
    "        j = int(j.replace('\\n', ''))\n",
    "        val = complex(main_concs.iloc[indexes[0][j], indexes[1][j]])\n",
    "        #test_indexes.append(unprocessed[(unprocessed['combination_name']==main_concs.columns[indexes[1][j]]) & (unprocessed['cell_line']==main_concs.index[indexes[0][j]]) & (unprocessed['drugA Conc (µM)']==val.real) & (unprocessed['drugB Conc (µM)']==val.imag)].index.values[0])\n",
    "        test_indexes.extend(unprocessed[(unprocessed['combination_name']==main_concs.columns[indexes[1][i]]) & (unprocessed['cell_line']==main_concs.index[indexes[0][i]])].index.values)\n",
    "        #print(main_concs.index[indexes[0][i]], main_concs.columns[indexes[1][i]])\n",
    "        #print(complex(main_concs.iloc[indexes[0][i], indexes[1][i]]).real)\n",
    "        #break\n",
    "    test_df = unprocessed[unprocessed.index.isin(test_indexes)]\n",
    "    test_df.to_csv(f'test_fold_{i}.csv', index=False)\n",
    "    test_df = unprocessed[~unprocessed.index.isin(test_indexes)]\n",
    "    test_df.to_csv(f'train_fold_{i}.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e253bf95",
   "metadata": {},
   "source": [
    "### cross validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61082d89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training on fold: 0\n",
      "Train samples: 8424, Test samples: 2106\n",
      "Iteration : 0\n",
      "Iteration : 10\n",
      "Iteration : 20\n",
      "Iteration : 30\n",
      "Iteration : 40\n",
      "Iteration : 50\n",
      "Iteration : 60\n",
      "Iteration : 70\n",
      "Iteration : 80\n",
      "Iteration : 90\n",
      "Iteration : 100\n",
      "Iteration : 110\n",
      "Iteration : 120\n",
      "Iteration : 130\n",
      "Iteration : 140\n",
      "Iteration : 150\n",
      "Iteration : 160\n",
      "Iteration : 170\n",
      "Iteration : 180\n",
      "Iteration : 190\n",
      "Iteration : 200\n",
      "Iteration : 210\n",
      "Iteration : 220\n",
      "Iteration : 230\n",
      "Iteration : 240\n",
      "Iteration : 250\n",
      "Iteration : 260\n",
      "Iteration : 270\n",
      "Iteration : 280\n",
      "Iteration : 290\n",
      "Final MAE: 2.2104\n",
      "Final MSE: 6.2854\n",
      "Final MAE (transformed): 9.2440\n",
      "Final MSE (transformed): 34.1616\n",
      "Validation accuracy: 0.3139\n",
      "\n",
      "Training on fold: 1\n",
      "Train samples: 8424, Test samples: 2106\n",
      "Iteration : 0\n",
      "Iteration : 10\n",
      "Iteration : 20\n",
      "Iteration : 30\n",
      "Iteration : 40\n",
      "Iteration : 50\n",
      "Iteration : 60\n",
      "Iteration : 70\n",
      "Iteration : 80\n",
      "Iteration : 90\n",
      "Iteration : 100\n",
      "Iteration : 110\n",
      "Iteration : 120\n",
      "Iteration : 130\n",
      "Iteration : 140\n",
      "Iteration : 150\n",
      "Iteration : 160\n",
      "Iteration : 170\n",
      "Iteration : 180\n",
      "Iteration : 190\n",
      "Iteration : 200\n",
      "Iteration : 210\n",
      "Iteration : 220\n",
      "Iteration : 230\n",
      "Iteration : 240\n",
      "Iteration : 250\n",
      "Iteration : 260\n",
      "Iteration : 270\n",
      "Iteration : 280\n",
      "Iteration : 290\n",
      "Final MAE: 2.2514\n",
      "Final MSE: 6.4646\n",
      "Final MAE (transformed): 9.8590\n",
      "Final MSE (transformed): 36.0939\n",
      "Validation accuracy: 0.2887\n",
      "\n",
      "Training on fold: 2\n",
      "Train samples: 8424, Test samples: 2106\n",
      "Iteration : 0\n",
      "Iteration : 10\n",
      "Iteration : 20\n",
      "Iteration : 30\n",
      "Iteration : 40\n",
      "Iteration : 50\n",
      "Iteration : 60\n",
      "Iteration : 70\n",
      "Iteration : 80\n",
      "Iteration : 90\n",
      "Iteration : 100\n",
      "Iteration : 110\n",
      "Iteration : 120\n",
      "Iteration : 130\n",
      "Iteration : 140\n",
      "Iteration : 150\n",
      "Iteration : 160\n",
      "Iteration : 170\n",
      "Iteration : 180\n",
      "Iteration : 190\n",
      "Iteration : 200\n",
      "Iteration : 210\n",
      "Iteration : 220\n",
      "Iteration : 230\n",
      "Iteration : 240\n",
      "Iteration : 250\n",
      "Iteration : 260\n",
      "Iteration : 270\n",
      "Iteration : 280\n",
      "Iteration : 290\n",
      "Final MAE: 2.2147\n",
      "Final MSE: 6.3138\n",
      "Final MAE (transformed): 11.0356\n",
      "Final MSE (transformed): 38.2436\n",
      "Validation accuracy: 0.3020\n",
      "\n",
      "Training on fold: 3\n",
      "Train samples: 8424, Test samples: 2106\n",
      "Iteration : 0\n",
      "Iteration : 10\n",
      "Iteration : 20\n",
      "Iteration : 30\n",
      "Iteration : 40\n",
      "Iteration : 50\n",
      "Iteration : 60\n",
      "Iteration : 70\n",
      "Iteration : 80\n",
      "Iteration : 90\n",
      "Iteration : 100\n",
      "Iteration : 110\n",
      "Iteration : 120\n",
      "Iteration : 130\n",
      "Iteration : 140\n",
      "Iteration : 150\n",
      "Iteration : 160\n",
      "Iteration : 170\n",
      "Iteration : 180\n",
      "Iteration : 190\n",
      "Iteration : 200\n",
      "Iteration : 210\n",
      "Iteration : 220\n",
      "Iteration : 230\n",
      "Iteration : 240\n",
      "Iteration : 250\n",
      "Iteration : 260\n",
      "Iteration : 270\n",
      "Iteration : 280\n",
      "Iteration : 290\n",
      "Final MAE: 2.1793\n",
      "Final MSE: 6.0731\n",
      "Final MAE (transformed): 9.8983\n",
      "Final MSE (transformed): 35.9097\n",
      "Validation accuracy: 0.3205\n",
      "\n",
      "Training on fold: 4\n",
      "Train samples: 8424, Test samples: 2106\n",
      "Iteration : 0\n",
      "Iteration : 10\n",
      "Iteration : 20\n",
      "Iteration : 30\n",
      "Iteration : 40\n",
      "Iteration : 50\n",
      "Iteration : 60\n",
      "Iteration : 70\n",
      "Iteration : 80\n",
      "Iteration : 90\n",
      "Iteration : 100\n",
      "Iteration : 110\n",
      "Iteration : 120\n",
      "Iteration : 130\n",
      "Iteration : 140\n",
      "Iteration : 150\n",
      "Iteration : 160\n",
      "Iteration : 170\n",
      "Iteration : 180\n",
      "Iteration : 190\n",
      "Iteration : 200\n",
      "Iteration : 210\n",
      "Iteration : 220\n",
      "Iteration : 230\n",
      "Iteration : 240\n",
      "Iteration : 250\n",
      "Iteration : 260\n",
      "Iteration : 270\n",
      "Iteration : 280\n",
      "Iteration : 290\n",
      "Final MAE: 2.2013\n",
      "Final MSE: 6.2208\n",
      "Final MAE (transformed): 9.7788\n",
      "Final MSE (transformed): 35.6520\n",
      "Validation accuracy: 0.2963\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "from tqdm import tqdm\n",
    "\n",
    "def pmf_with_bias(X: np.array, test: np.array, k: int, learning_rate: float, num_iterations: int, lambda_reg: float):\n",
    "    \"\"\"\n",
    "    Probabilistic Matrix Factorization with user and item bias using stochastic gradient descent for complex numbers.\n",
    "    \n",
    "    Arguments:\n",
    "    X -- Input matrix of shape (m, n) with complex numbers\n",
    "    test -- Test matrix of the same shape as X with complex numbers\n",
    "    k -- Number of latent features\n",
    "    learning_rate -- Learning rate for gradient descent\n",
    "    num_iterations -- Number of iterations for the optimization\n",
    "    lambda_reg -- Regularization strength\n",
    "    sigma_sq -- Variance of the complex Gaussian distribution\n",
    "    \n",
    "    Returns:\n",
    "    U -- Matrix of shape (m, k) representing the user latent factors (complex)\n",
    "    V -- Matrix of shape (n, k) representing the item latent factors (complex)\n",
    "    b_u -- Vector of shape (m,) representing the user bias terms (real)\n",
    "    b_v -- Vector of shape (n,) representing the item bias terms (real)\n",
    "    \"\"\"\n",
    "    m, n = X.shape\n",
    "\n",
    "    # Initialize U, V, b_u, and b_v with random values\n",
    "    U = np.random.normal(scale=1.0 / k, size=(m, k)).astype(complex)\n",
    "    V = np.random.normal(scale=1.0 / k, size=(n, k)).astype(complex)\n",
    "    b_u = np.random.normal(scale=1.0 / k, size= m).astype(complex) \n",
    "    b_v = np.random.normal(scale=1.0 / k, size=n).astype(complex)\n",
    "    \n",
    "    for iteration in range(num_iterations):\n",
    "        for i in range(m):\n",
    "            for j in range(n):\n",
    "                if X[i,j]!=0:\n",
    "                    prediction = np.dot(U[i, :], V[j, :].conj()) + b_u[i] + b_v[j]\n",
    "                    error = X[i, j] - prediction\n",
    "                    grad_U = -error * V[j, :] + lambda_reg * U[i, :]\n",
    "                    grad_V = -error * U[i, :] + lambda_reg * V[j, :]\n",
    "                    grad_b_u = -error + lambda_reg * b_u[i]\n",
    "                    grad_b_v = -error + lambda_reg * b_v[j]\n",
    "\n",
    "                    U[i, :] -= learning_rate * grad_U\n",
    "                    V[j, :] -= learning_rate * grad_V\n",
    "                    b_u[i] -= learning_rate * grad_b_u\n",
    "                    b_v[j] -= learning_rate * grad_b_v\n",
    "\n",
    "                    prediction = np.clip(prediction, -14, 9)\n",
    "\n",
    "        if iteration % 10 == 0:\n",
    "            print('Iteration : ' + str(iteration))\n",
    "            #print('MAE train error')\n",
    "            mask = np.nonzero(X)\n",
    "            #print(np.mean(abs(X[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask])))\n",
    "            mask = np.nonzero(test)\n",
    "            #print('MAE test error')\n",
    "            mae_loss = np.mean(abs(test[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask]))\n",
    "            #print(mae_loss)\n",
    "\n",
    "            #print('MSE train error')\n",
    "            mask = np.nonzero(X)\n",
    "            #print(np.mean(pow(abs(X[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask]), 2)))\n",
    "            mask = np.nonzero(test)\n",
    "            #print('MSE test error')\n",
    "            mse_loss = np.mean(pow(abs(test[mask]-(np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :])[mask]), 2))\n",
    "            #print(mse_loss)\n",
    "\n",
    "            pred = np.dot(U, V.T)+b_u[:, np.newaxis]+b_v[np.newaxis, :]\n",
    "            mask_pred = pred[mask]\n",
    "            mask_test = test[mask]\n",
    "            mask_test_real = list()\n",
    "            mask_pred_real = list()\n",
    "            error=0\n",
    "            c=0\n",
    "            for i in range(len(mask_test)):\n",
    "                a = complex(np.power(2, mask_test[i].real), np.power(2, mask_test[i].imag))\n",
    "                b = complex(np.power(2, mask_pred[i].real), np.power(2, mask_pred[i].imag))\n",
    "                mask_test_real.append(a)\n",
    "                mask_pred_real.append(b)\n",
    "            \n",
    "            mae_loss_transformed = np.mean(np.abs(np.array(mask_test_real) - np.array(mask_pred_real)))\n",
    "            #print(f'converted MAE transformed : {mae_loss_transformed}')\n",
    "            mse_loss_transformed = np.sqrt(np.mean(np.power(np.abs(np.array(mask_test_real) - np.array(mask_pred_real)), 2)))\n",
    "            #print(f'converted MSE transformed : {mse_loss_transformed}')\n",
    "    return U, V, b_u, b_v, mae_loss, mse_loss, mae_loss_transformed, mse_loss_transformed\n",
    "\n",
    "\n",
    "def load_fold_indices(fold, base_path=\"../Datasets/Oneil/\"):\n",
    "    \"\"\"Load train and test indices for a given fold\"\"\"\n",
    "    train_path = f\"{base_path}train_index_fold_{fold}.txt\"\n",
    "    test_path = f\"{base_path}test_index_fold_{fold}.txt\"\n",
    "    return (\n",
    "        np.loadtxt(train_path, dtype=int),\n",
    "        np.loadtxt(test_path, dtype=int)\n",
    "    )\n",
    "\n",
    "def create_train_test_matrices(ratings, indexes, train_idx, test_idx):\n",
    "    \"\"\"Create train and test matrices from indices\"\"\"\n",
    "    train = np.zeros_like(ratings, dtype=complex)\n",
    "    test = np.zeros_like(ratings, dtype=complex)\n",
    "    \n",
    "    for temp in train_idx:\n",
    "        train[tuple(indexes[temp])] = ratings[tuple(indexes[temp])]\n",
    "    for temp in test_idx:\n",
    "        test[tuple(indexes[temp])] = ratings[tuple(indexes[temp])]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "def calculate_validation_accuracy(t, test_idx, indexes, unprocessed, data):\n",
    "    \"\"\"Calculate validation accuracy by comparing predictions to ground truth\"\"\"\n",
    "    c = 0\n",
    "    for i in test_idx:\n",
    "        row, col = indexes[i]\n",
    "        cell_line = data.index[row]\n",
    "        combo_name = data.columns[col]\n",
    "        pred = t[row, col]\n",
    "        \n",
    "        combs = unprocessed[\n",
    "            (unprocessed['cell_line'] == cell_line) & \n",
    "            (unprocessed['combination_name'] == combo_name)\n",
    "        ][['ic50', 'new drugA Conc (µM)', 'new drugB Conc (µM)', 'X/X0']]\n",
    "        \n",
    "        # Find nearest concentrations\n",
    "        a = min(combs['new drugA Conc (µM)'].unique(), \n",
    "                key=lambda t: abs(pred.real - t))\n",
    "        b = min(combs['new drugB Conc (µM)'].unique(), \n",
    "                key=lambda t: abs(pred.imag - t))\n",
    "        \n",
    "        # Check if prediction falls in valid range\n",
    "        pred_conc = combs[\n",
    "            (combs['new drugA Conc (µM)'] == a) & \n",
    "            (combs['new drugB Conc (µM)'] == b)]\n",
    "        if pred_conc[(pred_conc['X/X0'] >= 0.44) & (pred_conc['X/X0'] <= 0.56)].shape[0] > 0:\n",
    "            c += 1\n",
    "            \n",
    "    return c / len(test_idx)\n",
    "\n",
    "def run_cross_validation(data, unprocessed, n_folds=5, pmf_params=None):\n",
    "    \"\"\"Run full cross-validation pipeline\"\"\"\n",
    "    if pmf_params is None:\n",
    "        pmf_params = {\n",
    "            'n_features': 700,\n",
    "            'learning_rate': 0.001,\n",
    "            'n_epochs': 300,\n",
    "            'reg_param': 0.0001        \n",
    "            }\n",
    "    \n",
    "    ratings = data.to_numpy(dtype='complex')\n",
    "    result_np = ratings.copy()\n",
    "    indexes = np.argwhere(result_np != complex(0, 0))\n",
    "    \n",
    "    for fold in range(n_folds):\n",
    "        print(f'\\nTraining on fold: {fold}')\n",
    "        \n",
    "        # Load fold data\n",
    "        train_idx, test_idx = load_fold_indices(fold)\n",
    "        print(f\"Train samples: {len(train_idx)}, Test samples: {len(test_idx)}\")\n",
    "        \n",
    "        # Create train/test matrices\n",
    "        train, test = create_train_test_matrices(ratings, indexes, train_idx, test_idx)\n",
    "        \n",
    "        # Run PMF with bias\n",
    "        U, V, b_u, b_v, mae, mse, mae_t, mse_t = pmf_with_bias(\n",
    "            train, test, \n",
    "            pmf_params['n_features'], \n",
    "            pmf_params['learning_rate'], \n",
    "            pmf_params['n_epochs'], \n",
    "            pmf_params['reg_param']\n",
    "        )\n",
    "        \n",
    "        # Calculate predictions\n",
    "        t = np.dot(U, V.T) + b_u[:, np.newaxis] + b_v[np.newaxis, :]\n",
    "        \n",
    "        # Calculate validation accuracy\n",
    "        val_acc = calculate_validation_accuracy(t, test_idx, indexes, unprocessed, data)\n",
    "        \n",
    "        # Print results\n",
    "        print(f'Final MAE: {mae:.4f}')\n",
    "        print(f'Final MSE: {mse:.4f}')\n",
    "        print(f'Final MAE (transformed): {mae_t:.4f}')\n",
    "        print(f'Final MSE (transformed): {mse_t:.4f}')\n",
    "        print(f'Validation accuracy: {val_acc:.4f}')\n",
    "\n",
    "# Example usage:\n",
    "run_cross_validation(data, unprocessed, n_folds=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a7d44d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
